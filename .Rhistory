boxplot(home_numerical$SalePrice, main = "SalePrice", cex.main = 0.8, cex.axis = 0.5, cex.lab = 0.5)
library(e1071)
cat("Data skewness is", skewness(home$SalePrice))
par(mfrow=c(1,3))
hist(log(home$SalePrice), cex.main = 1.2, main = "log(SalePrice)")
boxplot(log(home_numerical[,"SalePrice"]),cex.main = 1.2)
qqnorm(log(home_numerical$SalePrice),cex.main = 1.2)
# Correlation matrix for numerical features
library(corrplot)
R = round(cor(home_numerical),2)
corrplot(R, method='ellipse', tl.cex = 0.5)
par(mfrow=c(1,3))
# Surface
hist((home_numerical$`1stFlrSF`), main = "1stFloorSF", cex.main = 0.8)
boxplot((home_numerical$`1stFlrSF`), main = "1stFloorSF", cex.main = 0.8)
qqnorm(home_numerical$`1stFlrSF`,cex.main = 1.2)
home_numerical_output = home_numerical$SalePrice
home_numerical_features = home_numerical[,2:ncol(home_numerical)] # we will perform the PCA analysis on this dataset.
pca.train = home_numerical_features
prin_comp = prcomp(pca.train, center = TRUE, scale. = TRUE)
# Compute standard deviation of each principal component
std_dev = prin_comp$sdev
# Compute variance
pr_var = std_dev^2
prop_varex = pr_var/sum(pr_var)
# Cumulative scree plot
plot(cumsum(prop_varex),
xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
abline(h=1, col='red')
abline(v=19, col='black', lty = 3)
par(mfrow=c(1,3))
# Getting our factors
factors = unlist(lapply(home, is.factor))
home_factors = home[,factors]
# Street
barplot(table(home_factors$Street)[order(table(home_factors$Street))], main = "Street")
# Neighbourhood
barplot(table(home_factors$Neighborhood)[order(table(home_factors$Neighborhood))], main = "Neighbourhood")
# Garage Finish
barplot(table(home_factors$GarageFinish)[order(table(home_factors$GarageFinish))], main = "GarageFinish")
levels(home$OverallQual) = c("-4.3","-3.3","-2.4", "-1.6", "-0.8", "-0.0", "0.7", "1.4", "2.0", "2.7")
home$MSZoning = factor(home$MSZoning,levels(home$MSZoning)[c(1,3,5,4,2)])
library(gridExtra)
# Area
par(mfrow=c(1,2))
library(ggplot2)
plot1 = ggplot(home,
aes(x=MSZoning,
y=SalePrice,
colour=MSZoning,
group = MSZoning,
fill = MSZoning)) + geom_boxplot(alpha=0.5, outlier.alpha=0) +geom_jitter(width=0.1)
# Overall quality
plot2 = ggplot(home,
aes(x=OverallQual,
y=SalePrice,
colour= OverallQual,
group = OverallQual,
fill = OverallQual)) + geom_boxplot(alpha=0.5, outlier.alpha=0) +geom_jitter(width=0.1)
grid.arrange(plot1,plot2,ncol=2)
# Anova on area
mod1 = lm(SalePrice ~ MSZoning-1 , data=home)
anova(mod1)
# Anova on OverallQual
mod2 = lm(SalePrice ~ OverallQual-1 , data=home)
anova(mod2)
# ANCOVA on quality and area
mod3 = lm(SalePrice~1 + MSZoning + OverallQual + OverallQual:MSZoning, data = home)
anova(mod3)
winsor1 <- function (x, fraction=.05)
{if(length(fraction) != 1 || fraction < 0 ||fraction > 0.5) {stop("bad value for 'fraction'")}
lim <- quantile(x, probs=c(fraction, 1-fraction))
x[ x < lim[1] ] <- lim[1]
x[ x > lim[2] ] <- lim[2]
x}
# Ancova on OverallQual and OverallCond
mod5 = lm(SalePrice~1 + OverallQual + OverallCond + OverallQual:OverallCond, data = home)
anova(mod5)
col_to_remove = c("Street", "Utilities", "RoofMatl", "Condition2","Heating", "Electrical", "Functional", "GarageCond","Exterior1st", "Exterior2nd", "OverallCond", "HeatingQC", "SaleCondition", "BsmtFinType2","RoofStyle", "ExterQual")
for (name in col_to_remove){cat(which(colnames(home)==name)," ")}
# Elementary pruning and regrouping of categories
# Regrouping neighbourhoods of less than 20 and 50 sales together
table_neighborhood= table(home$Neighborhood)
table_neighborhood[order(table_neighborhood)]
levels(home$Neighborhood) <- c(levels(home$Neighborhood), "N_Under20Sales","N_Under50Sales")
home$Neighborhood[home$Neighborhood %in% c("Blueste","NPkVill","Veenker","BrDale","Blmngtn","MeadowV")] = "N_Under20Sales"
home$Neighborhood[home$Neighborhood %in% c("StoneBr","SWISU","ClearCr","IDOTRR","Timber","NoRidge","Mitchel")] = "N_Under50Sales"
# Roofstyle
table(home$RoofStyle)[order(table(home$RoofStyle))]
levels(home$RoofStyle) <- c(levels(home$RoofStyle), "RS_Other")
home$RoofStyle[home$RoofStyle %in% c("Shed","Mansard","Gambrel","Flat")] = "RS_Other"
# Condition 1
table(home$Condition1)[order(table(home$Condition1))]
levels(home$Condition1) <- c(levels(home$Condition1), "C_Other")
home$Condition1[home$Condition1 %in% c("RRNe","RRNn","PosA","RRAe","PosN","RRAn","Artery")] = "C_Other"
# ExterCond
table(home$ExterCond)[order(table(home$ExterCond))]
levels(home$ExterCond) <- c(levels(home$ExterCond), "EC_Other")
home$ExterCond[home$ExterCond %in% c("Po", "Ex", "Fa", "Gd")] = "EC_Other"
# OverallQual
table(home$OverallQual)
levels(home$OverallQual) <- c(levels(home$OverallQual), "Very_Low")
home$OverallQual[home$OverallQual %in% c("-4.3", "-3.3", "-2.4")] = "Very_Low"
home_streamlined = home[-c(5, 8, 21, 13, 22, 23, 40, 66, 34, 37, 20, 59, 26, 55, 62, 38, 51, 17)]
full_model1 = lm(log(SalePrice)~., data = home_streamlined)
summary(full_model1)
# Reducing our number of features using the 3 selection methods seen in class (forward, backward, both)
library(MASS)
# Forward method :
linear_select_variables_forward = stepAIC(full_model1, data=home_streamlined, trace=0, direction=c("forward"), verbose = FALSE)
# Backward method
linear_select_variables_backward = stepAIC(full_model1,~., trace=0, direction=c("backward") )
# Both
linear_select_variables_both = stepAIC(full_model1, trace=0, direction=c("both"))
extractAIC(linear_select_variables_forward)
extractAIC(linear_select_variables_backward)
extractAIC(linear_select_variables_both)
# Validate (or not) the postulates
par(mfrow=c(3,3))
plot(linear_select_variables_backward, which=1) # P1
plot(linear_select_variables_backward, which=3) # P2
acf(residuals(linear_select_variables_backward), main= "Auto-correlation plot") # P3
plot(linear_select_variables_backward, which=2) # P4
plot(linear_select_variables_backward, which=5) # Cook
library(car)
influenceIndexPlot(linear_select_variables_backward)
# Finding the outliers of our model
outlierTest(linear_select_variables_backward)
# Plotting our regression outliers
home_streamlined[c(199, 596, 336, 618, 633, 692, 323, 809),1:ncol(home_streamlined)]
# Building the dataframe without those outliers
home_no_outliers = home_streamlined[-c(199, 596, 336, 618, 633, 692, 323, 809), ]
# Displaying our regression model to use it on our new dataframe without outliers
linear_select_variables_backward
# The first model we will examine is the following:
model1 = lm(formula = log(SalePrice) ~ MSSubClass + MSZoning + LotFrontage +
LotArea + LandContour + LotConfig + LandSlope + Neighborhood +
Condition1 + OverallQual + YearBuilt + YearRemodAdd + MasVnrType +
MasVnrArea + ExterCond + Foundation + BsmtCond + BsmtExposure +
BsmtFinSF1 + BsmtUnfSF + CentralAir + GrLivArea + BsmtFullBath +
FullBath + HalfBath + KitchenQual + Fireplaces + GarageType +
GarageCars + GarageQual + WoodDeckSF + MoSold + YrSold, data = home_no_outliers)
summary(model1)
# Testing the postulates on our model 1
par(mfrow=c(3,3))
plot(model1, which=1) # P1
plot(model1, which=3) # P2
acf(residuals(model1), main= "Auto-correlation plot") # P3
plot(model1, which=2) # P4
plot(model1, which=5) # Cook's distance
home_streamlined$SalePrice= (winsor1(home$SalePrice, fraction=.05))
full_model2 = lm(log(SalePrice)~., data = home_streamlined)
model2 = stepAIC(full_model2,~., trace=0, direction=c("backward") )
summary(model2)
par(mfrow=c(3,3))
plot(model2, which=1) # P1
plot(model2, which=3) # P2
acf(residuals(model2), main= "Auto-correlation plot") # P3
plot(model2, which=2) # P4
plot(model2, which=5) # Cook's distance
influenceIndexPlot(model2)
outlierTest(model2)
home_streamlined[c(199, 336, 596, 633),1:ncol(home_streamlined)]
home_no_outliers = home_streamlined[-c(199, 336, 596, 633), ]
model2
model2 = lm(formula = log(SalePrice) ~ MSSubClass + MSZoning + LotFrontage +
LotArea + LotConfig + Neighborhood + Condition1 + OverallQual +
YearBuilt + YearRemodAdd + MasVnrType + MasVnrArea + BsmtCond +
BsmtExposure + BsmtFinSF1 + BsmtUnfSF + TotalBsmtSF + CentralAir +
`1stFlrSF` + GrLivArea + BsmtFullBath + FullBath + HalfBath +
KitchenQual + Fireplaces + GarageType + GarageYrBlt + GarageCars +
GarageQual + WoodDeckSF + MoSold + YrSold, data = home_no_outliers)
#linear_backward_without_outliers
# Testing our model on the test set
test = test[,2:ncol(test)]
# Reaffecting test's features to factors
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
test$MoSold = as.factor(test$MoSold)
test$MSSubClass = as.factor(test$MSSubClass)
test$Fireplaces = as.factor(test$Fireplaces)
levels(test$OverallQual) = c("-4.3","-3.3","-2.4", "-1.6", "-0.8", "-0.0", "0.7", "1.4", "2.0", "2.7")
test$MSZoning = factor(test$MSZoning,levels(test$MSZoning)[c(1,3,5,4,2)])
# Regrouping neighbourhoods of less than 20 and 50 sales together
levels(test$Neighborhood) <- c(levels(test$Neighborhood), "N_Under20Sales","N_Under50Sales")
test$Neighborhood[test$Neighborhood %in% c("Blueste","NPkVill","Veenker","BrDale","Blmngtn","MeadowV")] = "N_Under20Sales"
test$Neighborhood[test$Neighborhood %in% c("StoneBr","SWISU","ClearCr","IDOTRR","Timber","NoRidge","Mitchel")] = "N_Under50Sales"
# Roofstyle
levels(test$RoofStyle) <- c(levels(test$RoofStyle), "RS_Other")
test$RoofStyle[test$RoofStyle %in% c("Shed","Mansard","Gambrel","Flat")] = "RS_Other"
# Condition 1
levels(test$Condition1) <- c(levels(test$Condition1), "C_Other")
test$Condition1[test$Condition1 %in% c("RRNe","RRNn","PosA","RRAe","PosN","RRAn","Artery")] = "C_Other"
# ExterCond
levels(test$ExterCond) <- c(levels(test$ExterCond), "EC_Other")
test$ExterCond[test$ExterCond %in% c("Po", "Ex", "Fa", "Gd")] = "EC_Other"
# OverallQual
levels(test$OverallQual) <- c(levels(test$OverallQual), "Very_Low")
test$OverallQual[test$OverallQual %in% c("-4.3", "-3.3", "-2.4")] = "Very_Low"
# We look for the average percentage of SalePrice that we fail to predict
sqrt(mean((test$SalePrice - exp(predict.lm(model1, test))) ^ 2))
sqrt(mean((test$SalePrice - exp(predict.lm(model2, test))) ^ 2))
model <- lm(SalePrice ~ LotArea, data=home)
plot(home$LotArea, home$SalePrice, xlab="LotArea", ylab="SalePrice", main="Regression", cex.main=0.8, cex.axis=0.5, cex.lab=0.5)
abline(model, col="lightblue")
newx <- seq(0, 7, by=0.05)
pred_interval <- predict(model, newdata=data.frame(LotArea=newx), interval="prediction",
level = 0.95)
lines(newx, pred_interval[,2], col="orange", lty=2)
lines(newx, pred_interval[,3], col="orange", lty=2)
model2
summary(model2)
model1
model1
model2
linear_backward_without_outliers
# Test error
sqrt(mean((test$SalePrice - exp(predict.lm(linear_backward_without_outliers, test))) ^ 2))
test = test[,2:ncol(test)]
# Reaffecting test's features to factors
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
test$MoSold = as.factor(test$MoSold)
test$MSSubClass = as.factor(test$MSSubClass)
knitr::opts_chunk$set(echo = FALSE)
load("DataProject.RData")
# Loading the preprocessed dataset
home = train[,2:ncol(train)]
#head(home)
summary(home)
cat("There are", sum(is.na(home)), "missing values in our dataframe.")
# Getting regressor types
#str(home, give.attr = FALSE)
home$OverallQual = as.factor(home$OverallQual)
home$OverallCond = as.factor(home$OverallCond)
home$MoSold = as.factor(home$MoSold)
home$MSSubClass = as.factor(home$MSSubClass)
home$Fireplaces = as.factor(home$Fireplaces)
# head(home)
# str(home)
# Extracting all numerical variables
nums = unlist(lapply(home, is.numeric))
home_numerical = (home[ , nums])
par(mfrow=c(1,2))
# A few observations on SalePrice.
hist(home_numerical$SalePrice, main = "SalePrice")
boxplot(home_numerical$SalePrice, main = "SalePrice")
cat("The mean of Saleprice is", mean(home_numerical$SalePrice), "whereas the median is higher at", median(home_numerical$SalePrice), "indicating that extreme values skew our data to the right.")
par(mfrow=c(1,3))
hist(log(home_numerical[,"SalePrice"]))
summary(model1)
summary(model2)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
load("DataProject.RData")
home = train[,2:ncol(train)]
head(home)
summary(home)
str(home, give.attr = FALSE)
home$OverallQual = as.factor(home$OverallQual)
home$OverallCond = as.factor(home$OverallCond)
home$MoSold = as.factor(home$MoSold)
home$MSSubClass = as.factor(home$MSSubClass)
home$Fireplaces = as.factor(home$Fireplaces)
cat("There are", sum(is.na(home)), "missing values in our dataframe.")
# Extracting all numerical variables
nums = unlist(lapply(home, is.numeric))
home_numerical = (home[ , nums])
par(mfrow=c(1,2))
# A few observations on SalePrice.
hist(home_numerical$SalePrice, main = "SalePrice", cex.main = 0.8, cex.axis = 0.5, cex.lab = 0.5)
boxplot(home_numerical$SalePrice, main = "SalePrice", cex.main = 0.8, cex.axis = 0.5, cex.lab = 0.5)
library(e1071)
cat("Data skewness is", skewness(home$SalePrice))
par(mfrow=c(1,3))
hist(log(home$SalePrice), cex.main = 1.2, main = "log(SalePrice)")
boxplot(log(home_numerical[,"SalePrice"]),cex.main = 1.2)
qqnorm(log(home_numerical$SalePrice),cex.main = 1.2)
# Correlation matrix for numerical features
library(corrplot)
R = round(cor(home_numerical),2)
corrplot(R, method='ellipse', tl.cex = 0.5)
par(mfrow=c(1,3))
# Surface
hist((home_numerical$`1stFlrSF`), main = "1stFloorSF", cex.main = 0.8)
boxplot((home_numerical$`1stFlrSF`), main = "1stFloorSF", cex.main = 0.8)
qqnorm(home_numerical$`1stFlrSF`,cex.main = 1.2)
home_numerical_output = home_numerical$SalePrice
home_numerical_features = home_numerical[,2:ncol(home_numerical)] # we will perform the PCA analysis on this dataset.
pca.train = home_numerical_features
prin_comp = prcomp(pca.train, center = TRUE, scale. = TRUE)
# Compute standard deviation of each principal component
std_dev = prin_comp$sdev
# Compute variance
pr_var = std_dev^2
prop_varex = pr_var/sum(pr_var)
# Cumulative scree plot
plot(cumsum(prop_varex),
xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
abline(h=1, col='red')
abline(v=19, col='black', lty = 3)
par(mfrow=c(1,3))
# Getting our factors
factors = unlist(lapply(home, is.factor))
home_factors = home[,factors]
# Street
barplot(table(home_factors$Street)[order(table(home_factors$Street))], main = "Street")
# Neighbourhood
barplot(table(home_factors$Neighborhood)[order(table(home_factors$Neighborhood))], main = "Neighbourhood")
# Garage Finish
barplot(table(home_factors$GarageFinish)[order(table(home_factors$GarageFinish))], main = "GarageFinish")
levels(home$OverallQual) = c("-4.3","-3.3","-2.4", "-1.6", "-0.8", "-0.0", "0.7", "1.4", "2.0", "2.7")
home$MSZoning = factor(home$MSZoning,levels(home$MSZoning)[c(1,3,5,4,2)])
library(gridExtra)
# Area
par(mfrow=c(1,2))
library(ggplot2)
plot1 = ggplot(home,
aes(x=MSZoning,
y=SalePrice,
colour=MSZoning,
group = MSZoning,
fill = MSZoning)) + geom_boxplot(alpha=0.5, outlier.alpha=0) +geom_jitter(width=0.1)
# Overall quality
plot2 = ggplot(home,
aes(x=OverallQual,
y=SalePrice,
colour= OverallQual,
group = OverallQual,
fill = OverallQual)) + geom_boxplot(alpha=0.5, outlier.alpha=0) +geom_jitter(width=0.1)
grid.arrange(plot1,plot2,ncol=2)
# Anova on area
mod1 = lm(SalePrice ~ MSZoning-1 , data=home)
anova(mod1)
# Anova on OverallQual
mod2 = lm(SalePrice ~ OverallQual-1 , data=home)
anova(mod2)
# ANCOVA on quality and area
mod3 = lm(SalePrice~1 + MSZoning + OverallQual + OverallQual:MSZoning, data = home)
anova(mod3)
winsor1 <- function (x, fraction=.05)
{if(length(fraction) != 1 || fraction < 0 ||fraction > 0.5) {stop("bad value for 'fraction'")}
lim <- quantile(x, probs=c(fraction, 1-fraction))
x[ x < lim[1] ] <- lim[1]
x[ x > lim[2] ] <- lim[2]
x}
# Ancova on OverallQual and OverallCond
mod5 = lm(SalePrice~1 + OverallQual + OverallCond + OverallQual:OverallCond, data = home)
anova(mod5)
col_to_remove = c("Street", "Utilities", "RoofMatl", "Condition2","Heating", "Electrical", "Functional", "GarageCond","Exterior1st", "Exterior2nd", "OverallCond", "HeatingQC", "SaleCondition", "BsmtFinType2","RoofStyle", "ExterQual")
for (name in col_to_remove){cat(which(colnames(home)==name)," ")}
# Elementary pruning and regrouping of categories
# Regrouping neighbourhoods of less than 20 and 50 sales together
table_neighborhood= table(home$Neighborhood)
table_neighborhood[order(table_neighborhood)]
levels(home$Neighborhood) <- c(levels(home$Neighborhood), "N_Under20Sales","N_Under50Sales")
home$Neighborhood[home$Neighborhood %in% c("Blueste","NPkVill","Veenker","BrDale","Blmngtn","MeadowV")] = "N_Under20Sales"
home$Neighborhood[home$Neighborhood %in% c("StoneBr","SWISU","ClearCr","IDOTRR","Timber","NoRidge","Mitchel")] = "N_Under50Sales"
# Roofstyle
table(home$RoofStyle)[order(table(home$RoofStyle))]
levels(home$RoofStyle) <- c(levels(home$RoofStyle), "RS_Other")
home$RoofStyle[home$RoofStyle %in% c("Shed","Mansard","Gambrel","Flat")] = "RS_Other"
# Condition 1
table(home$Condition1)[order(table(home$Condition1))]
levels(home$Condition1) <- c(levels(home$Condition1), "C_Other")
home$Condition1[home$Condition1 %in% c("RRNe","RRNn","PosA","RRAe","PosN","RRAn","Artery")] = "C_Other"
# ExterCond
table(home$ExterCond)[order(table(home$ExterCond))]
levels(home$ExterCond) <- c(levels(home$ExterCond), "EC_Other")
home$ExterCond[home$ExterCond %in% c("Po", "Ex", "Fa", "Gd")] = "EC_Other"
# OverallQual
table(home$OverallQual)
levels(home$OverallQual) <- c(levels(home$OverallQual), "Very_Low")
home$OverallQual[home$OverallQual %in% c("-4.3", "-3.3", "-2.4")] = "Very_Low"
home_streamlined = home[-c(5, 8, 21, 13, 22, 23, 40, 66, 34, 37, 20, 59, 26, 55, 62, 38, 51, 17)]
full_model1 = lm(log(SalePrice)~., data = home_streamlined)
summary(full_model1)
# Reducing our number of features using the 3 selection methods seen in class (forward, backward, both)
library(MASS)
# Forward method :
linear_select_variables_forward = stepAIC(full_model1, data=home_streamlined, trace=0, direction=c("forward"), verbose = FALSE)
# Backward method
linear_select_variables_backward = stepAIC(full_model1,~., trace=0, direction=c("backward") )
# Both
linear_select_variables_both = stepAIC(full_model1, trace=0, direction=c("both"))
extractAIC(linear_select_variables_forward)
extractAIC(linear_select_variables_backward)
extractAIC(linear_select_variables_both)
# Validate (or not) the postulates
par(mfrow=c(3,3))
plot(linear_select_variables_backward, which=1) # P1
plot(linear_select_variables_backward, which=3) # P2
acf(residuals(linear_select_variables_backward), main= "Auto-correlation plot") # P3
plot(linear_select_variables_backward, which=2) # P4
plot(linear_select_variables_backward, which=5) # Cook
library(car)
influenceIndexPlot(linear_select_variables_backward)
# Finding the outliers of our model
outlierTest(linear_select_variables_backward)
# Plotting our regression outliers
home_streamlined[c(199, 596, 336, 618, 633, 692, 323, 809),1:ncol(home_streamlined)]
# Building the dataframe without those outliers
home_no_outliers = home_streamlined[-c(199, 596, 336, 618, 633, 692, 323, 809), ]
# Displaying our regression model to use it on our new dataframe without outliers
linear_select_variables_backward
# The first model we will examine is the following:
model1 = lm(formula = log(SalePrice) ~ MSSubClass + MSZoning + LotFrontage +
LotArea + LandContour + LotConfig + LandSlope + Neighborhood +
Condition1 + OverallQual + YearBuilt + YearRemodAdd + MasVnrType +
MasVnrArea + ExterCond + Foundation + BsmtCond + BsmtExposure +
BsmtFinSF1 + BsmtUnfSF + CentralAir + GrLivArea + BsmtFullBath +
FullBath + HalfBath + KitchenQual + Fireplaces + GarageType +
GarageCars + GarageQual + WoodDeckSF + MoSold + YrSold, data = home_no_outliers)
summary(model1)
# Testing the postulates on our model 1
par(mfrow=c(3,3))
plot(model1, which=1) # P1
plot(model1, which=3) # P2
acf(residuals(model1), main= "Auto-correlation plot") # P3
plot(model1, which=2) # P4
plot(model1, which=5) # Cook's distance
home_streamlined$SalePrice= (winsor1(home$SalePrice, fraction=.05))
full_model2 = lm(log(SalePrice)~., data = home_streamlined)
model2 = stepAIC(full_model2,~., trace=0, direction=c("backward") )
summary(model2)
par(mfrow=c(3,3))
plot(model2, which=1) # P1
plot(model2, which=3) # P2
acf(residuals(model2), main= "Auto-correlation plot") # P3
plot(model2, which=2) # P4
plot(model2, which=5) # Cook's distance
influenceIndexPlot(model2)
outlierTest(model2)
home_streamlined[c(199, 336, 596, 633),1:ncol(home_streamlined)]
home_no_outliers = home_streamlined[-c(199, 336, 596, 633), ]
model2
model2 = lm(formula = log(SalePrice) ~ MSSubClass + MSZoning + LotFrontage +
LotArea + LotConfig + Neighborhood + Condition1 + OverallQual +
YearBuilt + YearRemodAdd + MasVnrType + MasVnrArea + BsmtCond +
BsmtExposure + BsmtFinSF1 + BsmtUnfSF + TotalBsmtSF + CentralAir +
`1stFlrSF` + GrLivArea + BsmtFullBath + FullBath + HalfBath +
KitchenQual + Fireplaces + GarageType + GarageYrBlt + GarageCars +
GarageQual + WoodDeckSF + MoSold + YrSold, data = home_no_outliers)
summary(model2)
summary(model1)
summary(model2)
# Testing our model on the test set
test = test[,2:ncol(test)]
# Reaffecting test's features to factors
test$OverallQual = as.factor(test$OverallQual)
test$OverallCond = as.factor(test$OverallCond)
test$MoSold = as.factor(test$MoSold)
test$MSSubClass = as.factor(test$MSSubClass)
test$Fireplaces = as.factor(test$Fireplaces)
levels(test$OverallQual) = c("-4.3","-3.3","-2.4", "-1.6", "-0.8", "-0.0", "0.7", "1.4", "2.0", "2.7")
test$MSZoning = factor(test$MSZoning,levels(test$MSZoning)[c(1,3,5,4,2)])
# Regrouping neighbourhoods of less than 20 and 50 sales together
levels(test$Neighborhood) <- c(levels(test$Neighborhood), "N_Under20Sales","N_Under50Sales")
test$Neighborhood[test$Neighborhood %in% c("Blueste","NPkVill","Veenker","BrDale","Blmngtn","MeadowV")] = "N_Under20Sales"
test$Neighborhood[test$Neighborhood %in% c("StoneBr","SWISU","ClearCr","IDOTRR","Timber","NoRidge","Mitchel")] = "N_Under50Sales"
# Roofstyle
levels(test$RoofStyle) <- c(levels(test$RoofStyle), "RS_Other")
test$RoofStyle[test$RoofStyle %in% c("Shed","Mansard","Gambrel","Flat")] = "RS_Other"
# Condition 1
levels(test$Condition1) <- c(levels(test$Condition1), "C_Other")
test$Condition1[test$Condition1 %in% c("RRNe","RRNn","PosA","RRAe","PosN","RRAn","Artery")] = "C_Other"
# ExterCond
levels(test$ExterCond) <- c(levels(test$ExterCond), "EC_Other")
test$ExterCond[test$ExterCond %in% c("Po", "Ex", "Fa", "Gd")] = "EC_Other"
# OverallQual
levels(test$OverallQual) <- c(levels(test$OverallQual), "Very_Low")
test$OverallQual[test$OverallQual %in% c("-4.3", "-3.3", "-2.4")] = "Very_Low"
# We look for the average percentage of SalePrice that we fail to predict
sqrt(mean((test$SalePrice - exp(predict.lm(model1, test))) ^ 2))
sqrt(mean((test$SalePrice - exp(predict.lm(model2, test))) ^ 2))
model <- lm(SalePrice ~ LotArea, data=home)
plot(home$LotArea, home$SalePrice, xlab="LotArea", ylab="SalePrice", main="Regression", cex.main=0.8, cex.axis=0.5, cex.lab=0.5)
abline(model, col="lightblue")
newx <- seq(0, 7, by=0.05)
pred_interval <- predict(model, newdata=data.frame(LotArea=newx), interval="prediction",
level = 0.95)
lines(newx, pred_interval[,2], col="orange", lty=2)
lines(newx, pred_interval[,3], col="orange", lty=2)
knitr::opts_chunk$set(echo = FALSE)
load("DataProject.RData")
# Loading the preprocessed dataset
home = train[,2:ncol(train)]
#head(home)
summary(home)
cat("There are", sum(is.na(home)), "missing values in our dataframe.")
# Getting regressor types
#str(home, give.attr = FALSE)
home$OverallQual = as.factor(home$OverallQual)
home$OverallCond = as.factor(home$OverallCond)
home$MoSold = as.factor(home$MoSold)
home$MSSubClass = as.factor(home$MSSubClass)
home$Fireplaces = as.factor(home$Fireplaces)
# head(home)
# str(home)
# Extracting all numerical variables
nums = unlist(lapply(home, is.numeric))
home_numerical = (home[ , nums])
par(mfrow=c(1,2))
# A few observations on SalePrice.
hist(home_numerical$SalePrice, main = "SalePrice")
boxplot(home_numerical$SalePrice, main = "SalePrice")
cat("The mean of Saleprice is", mean(home_numerical$SalePrice), "whereas the median is higher at", median(home_numerical$SalePrice), "indicating that extreme values skew our data to the right.")
par(mfrow=c(1,3))
hist(log(home_numerical[,"SalePrice"]))
